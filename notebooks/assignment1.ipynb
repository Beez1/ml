{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(\"..\") \n",
    "sys.path.append(os.path.join(project_root, \"scripts\"))\n",
    "from linear_regression import LinearRegressionGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "data_path = \"../data/insurance.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Display dataset information\n",
    "print(\"Data loaded successfully!\")\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(\"Columns:\", df.columns)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "if df is not None:\n",
    "    # Drop index column if it exists\n",
    "    df = df.drop(columns=['index'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Drop index column if it exists\n",
    "    df = df.drop(columns=['index'], errors='ignore')\n",
    "    \n",
    "    # Feature Engineering\n",
    "    # BMI Categories\n",
    "    df['bmi_category'] = pd.cut(df['bmi'], \n",
    "                            bins=[0, 18.5, 25, 30, float('inf')], \n",
    "                            labels=['Underweight', 'Normal', 'Overweight', 'Obese'])\n",
    "    \n",
    "    # Age × BMI interaction\n",
    "    df['age_bmi_interaction'] = df['age'] * df['bmi']\n",
    "    \n",
    "    # Define features\n",
    "    categorical_features = ['sex', 'smoker', 'region', 'bmi_category']\n",
    "    numerical_features = ['age', 'bmi', 'children', 'age_bmi_interaction']\n",
    "    \n",
    "    # One-Hot Encoding\n",
    "    ohe = ColumnTransformer([\n",
    "        ('encoder', OneHotEncoder(drop='first'), categorical_features)\n",
    "    ], remainder='passthrough')\n",
    "    \n",
    "    # Extract features and target\n",
    "    features = ohe.fit_transform(df.drop(columns=['charges']))\n",
    "    target = np.log(df['charges'].values)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Features Shape: {features.shape}, Target Shape: {target.shape}\")\n",
    "    print(\"\\nFirst 5 Log-Transformed Target Values (y):\")\n",
    "    print(target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize only numerical features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Identify numeric feature indices (assumes categorical features are first in `features`)\n",
    "num_features_start = len(ohe.named_transformers_['encoder'].get_feature_names_out())\n",
    "X_train[:, num_features_start:] = scaler.fit_transform(X_train[:, num_features_start:])\n",
    "X_test[:, num_features_start:] = scaler.transform(X_test[:, num_features_start:])\n",
    "\n",
    "# Confirm the split\n",
    "print(f\"Training Set Shape: {X_train.shape}, Testing Set Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Linear Regression model\n",
    "try:\n",
    "    lr = LinearRegressionGD(learning_rate=0.001, n_iter=5000)  # n_iter specifies the number of iterations/epochs for gradient descent optimization\n",
    "\n",
    "    print(\"Custom Linear Regression model imported successfully!\")\n",
    "except NameError:\n",
    "    print(\"Error: LinearRegressionGD is not defined. Ensure it's correctly imported.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Train the custom model\n",
    "    print(\"Training and evaluating custom model...\")\n",
    "    lr_custom = LinearRegressionGD(learning_rate=0.001, n_iter=5000)\n",
    "    # Fit custom model\n",
    "    lr_custom.fit(X_train, y_train)\n",
    "    # Predict using custom model\n",
    "    y_pred_custom = lr_custom.predict(X_test)\n",
    "    # Calculate MSE for custom model\n",
    "    mse_custom = mean_squared_error(y_test, y_pred_custom)\n",
    "\n",
    "    # Train the scikit-learn model\n",
    "    print(\"Training and evaluating scikit-learn model...\")\n",
    "    lr_sklearn = LinearRegression()\n",
    "    # Fit scikit-learn model\n",
    "    lr_sklearn.fit(X_train, y_train)\n",
    "    # Predict using scikit-learn model\n",
    "    y_pred_sklearn = lr_sklearn.predict(X_test)\n",
    "    # Calculate MSE for scikit-learn model\n",
    "    mse_sklearn = mean_squared_error(y_test, y_pred_sklearn)\n",
    "\n",
    "    # Print comparison of model performances\n",
    "    print(\"\\nModel Performance Comparison:\")\n",
    "    print(f\"Custom Model MSE on Test Set:            {mse_custom:.4f}\")\n",
    "    print(f\"scikit-learn Linear Regression MSE:      {mse_sklearn:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during model training/evaluation: {str(e)}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(lr, 'costs') and len(lr.costs) > 0:\n",
    "    print(\"Cost values exist, proceeding with plotting.\")\n",
    "else:\n",
    "    print(\"No cost values recorded. Ensure the model has been trained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of actual vs predicted values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred_custom, alpha=0.5, label=\"Custom Model Predictions\", color=\"blue\")\n",
    "plt.scatter(y_test, y_pred_sklearn, alpha=0.5, label=\"SKLearn Model Predictions\", color=\"green\")\n",
    "\n",
    "# Add the reference line (Perfect Predictions)\n",
    "min_val = np.min([y_test.min(), y_pred_custom.min(), y_pred_sklearn.min()])\n",
    "max_val = np.max([y_test.max(), y_pred_custom.max(), y_pred_sklearn.max()])\n",
    "plt.plot([min_val, max_val], [min_val, max_val], linestyle='--', color='red', label=\"Perfect Predictions\")\n",
    "\n",
    "plt.xlabel('Actual Charges (log-transformed)')\n",
    "plt.ylabel('Predicted Charges (log-transformed)')\n",
    "plt.title('Actual vs Predicted Values: Custom vs SKLearn Models')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Compare predictions from the custom and scikit-learn models\n",
    "print(\"\\nComparison of Models:\")\n",
    "print(f\"Custom Model MSE: {mse_custom:.4f}\")  # mse from custom model earlier\n",
    "print(f\"scikit-learn Model MSE: {mse_sklearn:.4f}\")\n",
    "print(f\"Custom Model R² Score: {r2_score(y_test, y_pred_custom):.4f}\")\n",
    "print(f\"scikit-learn R² Score: {r2_score(y_test, y_pred_sklearn):.4f}\")\n",
    "\n",
    "# Plot comparison of predictions: Custom vs scikit-learn\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_custom, alpha=0.5, label=\"Custom Model Predictions\", color=\"blue\")\n",
    "plt.scatter(y_test, y_pred_sklearn, alpha=0.5, label=\"scikit-learn Predictions\", color=\"green\")\n",
    "\n",
    "# Draw the line of perfect prediction\n",
    "min_val = np.min([y_test.min(), y_pred_custom.min(), y_pred_sklearn.min()])\n",
    "max_val = np.max([y_test.max(), y_pred_custom.max(), y_pred_sklearn.max()])\n",
    "plt.plot([min_val, max_val], [min_val, max_val], linestyle='--', color='red', label=\"Perfect Prediction\")\n",
    "\n",
    "plt.xlabel('Actual Charges (log-transformed)')\n",
    "plt.ylabel('Predicted Charges (log-transformed)')\n",
    "plt.title('Comparison of Predictions: Custom vs scikit-learn')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "residuals_custom = y_test - y_pred_custom\n",
    "plt.scatter(y_pred_custom, residuals_custom, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot - Custom Model')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals_sklearn = y_test - y_pred_sklearn\n",
    "plt.scatter(y_pred_sklearn, residuals_sklearn, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot - Scikit-learn Model')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analysis & Reporting\n",
    "print(\"\\n--- Analysis & Reporting ---\")\n",
    "print(\"1. Performance Metrics:\")\n",
    "print(\"   - The custom Linear Regression model using gradient descent achieved:\")\n",
    "print(\"     * MSE: {:.4f}\".format(mse_custom))\n",
    "print(\"     * R² Score: {:.4f}\".format(r2_score(y_test, y_pred_custom)))\n",
    "print(\"   - The scikit-learn Linear Regression model achieved:\")\n",
    "print(\"     * MSE: {:.4f}\".format(mse_sklearn))\n",
    "print(\"     * R² Score: {:.4f}\".format(r2_score(y_test, y_pred_sklearn)))\n",
    "\n",
    "print(\"\\n2. Visual Analysis:\")\n",
    "print(\"   - The prediction scatter plot shows both models' predictions against actual log-transformed charges.\")\n",
    "print(\"   - The residual plots help visualize the distribution of prediction errors and identify any patterns.\")\n",
    "print(\"   - Both models' predictions lie close to the perfect prediction line, indicating good performance.\")\n",
    "\n",
    "print(\"\\n3. Discussion:\")\n",
    "print(\"   - The close MSE and R² values between models validate the custom implementation.\")\n",
    "print(\"   - The residual plots show whether the models' errors are randomly distributed or show systematic patterns.\")\n",
    "print(\"   - Minor differences may be due to differences in optimization details between implementations.\")\n",
    "print(\"   - The log-transformation of the target variable helps stabilize variance and improve model performance.\")\n",
    "\n",
    "print(\"\\n4. Conclusion:\")\n",
    "print(\"   - Both models demonstrate similar performance across multiple metrics.\")\n",
    "print(\"   - The residual analysis provides additional confidence in the models' predictions.\")\n",
    "print(\"   - The exercise successfully validates the custom implementation against an established library.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
